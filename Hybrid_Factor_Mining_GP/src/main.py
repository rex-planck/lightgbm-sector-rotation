"""
é¡¹ç›®ä¸»å…¥å£
æ•´åˆæ•°æ®è·å–ã€å› å­æŒ–æ˜ã€æ¨¡å‹è®­ç»ƒçš„å…¨æµç¨‹
"""
import argparse
import os
import sys

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

from config import TUSHARE_TOKEN


def check_config():
    """æ£€æŸ¥é…ç½®æ˜¯å¦å®Œæ•´"""
    if not TUSHARE_TOKEN:
        print("âŒ é”™è¯¯ï¼šè¯·åœ¨ src/config.py ä¸­è®¾ç½® TUSHARE_TOKEN")
        print("   è·å–æ–¹å¼ï¼šhttps://tushare.pro/register")
        return False
    return True


def run_data_fetch():
    """è¿è¡Œæ•°æ®è·å–"""
    print("\n" + "=" * 60)
    print("ğŸ“¥ æ­¥éª¤ 1/4: è·å– Tushare æ•°æ®")
    print("=" * 60)
    from data_fetcher import main as fetch_main
    fetch_main()


def run_data_prepare():
    """è¿è¡Œæ•°æ®é¢„å¤„ç†"""
    print("\n" + "=" * 60)
    print("ğŸ”§ æ­¥éª¤ 2/4: æ•°æ®é¢„å¤„ç†")
    print("=" * 60)
    from data_loader import DataLoader
    
    loader = DataLoader()
    df_raw = loader.load_all_data()
    df_features = loader.prepare_features(df_raw)
    df_labeled = loader.prepare_labels(df_features)
    
    # ä¿å­˜å¤„ç†åçš„æ•°æ®
    output_path = os.path.join(loader.db_path.replace('.db', '_processed.csv'))
    df_labeled.to_csv(output_path.replace('.db', '_processed.csv'), index=False)
    
    loader.close()
    print(f"âœ… æ•°æ®é¢„å¤„ç†å®Œæˆ")


def run_factor_mining():
    """è¿è¡Œå› å­æŒ–æ˜"""
    print("\n" + "=" * 60)
    print("ğŸ§¬ æ­¥éª¤ 3/4: GP å› å­æŒ–æ˜")
    print("=" * 60)
    from gp_factor_mining import main as gp_main
    gp_main()


def run_two_stage_model():
    """è¿è¡Œä¸¤é˜¶æ®µæ¨¡å‹"""
    print("\n" + "=" * 60)
    print("ğŸš€ æ­¥éª¤ 4/4: ä¸¤é˜¶æ®µæ¨¡å‹è®­ç»ƒ (GPå› å­ + GRU)")
    print("=" * 60)
    from two_stage_gru import main as gru_main
    gru_main()


def run_full_pipeline():
    """è¿è¡Œå®Œæ•´æµç¨‹"""
    if not check_config():
        return
    
    print("\n" + "=" * 60)
    print("ğŸ¯ å¯åŠ¨å®Œæ•´æµç¨‹: æ•°æ® â†’ å› å­æŒ–æ˜ â†’ GRUè®­ç»ƒ")
    print("=" * 60)
    
    try:
        run_data_fetch()
    except Exception as e:
        print(f"âš ï¸ æ•°æ®è·å–æ­¥éª¤å‡ºé”™ï¼ˆå¯èƒ½å·²æœ‰æ•°æ®ï¼‰: {e}")
    
    try:
        run_data_prepare()
    except Exception as e:
        print(f"âŒ æ•°æ®é¢„å¤„ç†å¤±è´¥: {e}")
        return
    
    try:
        run_factor_mining()
    except Exception as e:
        print(f"âŒ å› å­æŒ–æ˜å¤±è´¥: {e}")
        return
    
    try:
        run_two_stage_model()
    except Exception as e:
        print(f"âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
        return
    
    print("\n" + "=" * 60)
    print("ğŸ‰ å…¨æµç¨‹å®Œæˆï¼")
    print("=" * 60)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="åŸºäº GPlearn çš„'æœºç†+æ•°æ®'æ··åˆå› å­æŒ–æ˜ç³»ç»Ÿ"
    )
    parser.add_argument(
        "--step",
        choices=["all", "fetch", "prepare", "mine", "train"],
        default="all",
        help="é€‰æ‹©è¿è¡Œæ­¥éª¤: all=å…¨æµç¨‹, fetch=è·å–æ•°æ®, prepare=é¢„å¤„ç†, mine=å› å­æŒ–æ˜, train=æ¨¡å‹è®­ç»ƒ"
    )
    
    args = parser.parse_args()
    
    if args.step == "all":
        run_full_pipeline()
    elif args.step == "fetch":
        if check_config():
            run_data_fetch()
    elif args.step == "prepare":
        run_data_prepare()
    elif args.step == "mine":
        run_factor_mining()
    elif args.step == "train":
        run_two_stage_model()


if __name__ == "__main__":
    main()
