"""
ä¼˜åŒ–ç‰ˆ Tushare æ•°æ®è·å–æ¨¡å—
é’ˆå¯¹ 2000 ç§¯åˆ†è´¦æˆ·ä¼˜åŒ–ï¼š
1. ä½¿ç”¨æ‰¹é‡æ¥å£å‡å°‘ API è°ƒç”¨æ¬¡æ•°
2. æ·»åŠ æ™ºèƒ½é™æµæ§åˆ¶
3. æ”¯æŒæ–­ç‚¹ç»­ä¼ 
"""
import tushare as ts
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import List, Optional, Set
import sqlite3
import time
from tqdm import tqdm
import logging

from config import (
    TUSHARE_TOKEN, DB_PATH, INDEX_CODE,
    START_DATE, END_DATE
)

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class RateLimiter:
    """Tushare API é™é€Ÿå™¨ï¼ˆ2000ç§¯åˆ†ï¼šæ¯åˆ†é’Ÿ500æ¬¡ï¼‰"""
    
    def __init__(self, max_calls: int = 480, period: int = 60):
        """
        Args:
            max_calls: æ¯å‘¨æœŸæœ€å¤§è°ƒç”¨æ¬¡æ•°ï¼ˆç•™20æ¬¡ç¼“å†²ï¼‰
            period: å‘¨æœŸï¼ˆç§’ï¼‰
        """
        self.max_calls = max_calls
        self.period = period
        self.calls = []
    
    def wait_if_needed(self):
        """æ£€æŸ¥æ˜¯å¦éœ€è¦ç­‰å¾…"""
        now = time.time()
        # æ¸…ç†è¿‡æœŸè®°å½•
        self.calls = [c for c in self.calls if now - c < self.period]
        
        if len(self.calls) >= self.max_calls:
            sleep_time = self.period - (now - self.calls[0]) + 1
            logger.info(f"â³ é™é€Ÿç­‰å¾… {sleep_time:.1f} ç§’...")
            time.sleep(sleep_time)
            self.calls = []
        
        self.calls.append(time.time())


class TushareDataFetcherOptimized:
    """ä¼˜åŒ–ç‰ˆ Tushare æ•°æ®è·å–å™¨"""
    
    def __init__(self, token: Optional[str] = None):
        self.token = token or TUSHARE_TOKEN
        if not self.token:
            raise ValueError("è¯·æä¾› Tushare Token")
        
        self.pro = ts.pro_api(self.token)
        self.rate_limiter = RateLimiter()
        self._init_database()
        
        # æµ‹è¯• API
        self._test_api()
    
    def _test_api(self):
        """æµ‹è¯• API è¿æ¥"""
        try:
            self.rate_limiter.wait_if_needed()
            df = self.pro.trade_cal(exchange='', start_date='20240101', end_date='20240105')
            logger.info(f"âœ… API è¿æ¥æˆåŠŸï¼Œå‰©ä½™ç§¯åˆ†: {self._get_remaining_points()}")
        except Exception as e:
            logger.error(f"âŒ API è¿æ¥å¤±è´¥: {e}")
            raise
    
    def _get_remaining_points(self) -> int:
        """è·å–å‰©ä½™ç§¯åˆ†"""
        try:
            self.rate_limiter.wait_if_needed()
            df = self.pro.user()
            return df['remaining'].values[0] if 'remaining' in df.columns else -1
        except:
            return -1
    
    def _init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“ï¼ˆæ·»åŠ å…ƒæ•°æ®è¡¨ï¼‰"""
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        
        # åŸæœ‰è¡¨ç»“æ„
        tables = [
            ("stock_basic", """
                CREATE TABLE IF NOT EXISTS stock_basic (
                    ts_code TEXT PRIMARY KEY,
                    symbol TEXT,
                    name TEXT,
                    industry TEXT,
                    market TEXT,
                    list_date TEXT
                )
            """),
            ("daily_price", """
                CREATE TABLE IF NOT EXISTS daily_price (
                    ts_code TEXT,
                    trade_date TEXT,
                    open REAL,
                    high REAL,
                    low REAL,
                    close REAL,
                    pre_close REAL,
                    change REAL,
                    pct_chg REAL,
                    vol REAL,
                    amount REAL,
                    PRIMARY KEY (ts_code, trade_date)
                )
            """),
            ("adj_factor", """
                CREATE TABLE IF NOT EXISTS adj_factor (
                    ts_code TEXT,
                    trade_date TEXT,
                    adj_factor REAL,
                    PRIMARY KEY (ts_code, trade_date)
                )
            """),
            ("daily_basic", """
                CREATE TABLE IF NOT EXISTS daily_basic (
                    ts_code TEXT,
                    trade_date TEXT,
                    turnover_rate REAL,
                    turnover_rate_f REAL,
                    pe REAL,
                    pe_ttm REAL,
                    pb REAL,
                    total_mv REAL,
                    circ_mv REAL,
                    PRIMARY KEY (ts_code, trade_date)
                )
            """),
            ("index_weight", """
                CREATE TABLE IF NOT EXISTS index_weight (
                    index_code TEXT,
                    con_code TEXT,
                    trade_date TEXT,
                    weight REAL,
                    PRIMARY KEY (index_code, con_code, trade_date)
                )
            """),
            # æ–°å¢ï¼šå…ƒæ•°æ®è¡¨ï¼ˆç”¨äºæ–­ç‚¹ç»­ä¼ ï¼‰
            ("fetch_meta", """
                CREATE TABLE IF NOT EXISTS fetch_meta (
                    key TEXT PRIMARY KEY,
                    value TEXT,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)
        ]
        
        for name, sql in tables:
            cursor.execute(sql)
        
        conn.commit()
        conn.close()
        logger.info(f"âœ… æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ: {DB_PATH}")
    
    def _get_meta(self, key: str) -> Optional[str]:
        """è·å–å…ƒæ•°æ®"""
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        cursor.execute("SELECT value FROM fetch_meta WHERE key = ?", (key,))
        result = cursor.fetchone()
        conn.close()
        return result[0] if result else None
    
    def _set_meta(self, key: str, value: str):
        """è®¾ç½®å…ƒæ•°æ®"""
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        cursor.execute("""
            INSERT OR REPLACE INTO fetch_meta (key, value, updated_at)
            VALUES (?, ?, CURRENT_TIMESTAMP)
        """, (key, value))
        conn.commit()
        conn.close()
    
    def fetch_stock_basic(self) -> pd.DataFrame:
        """è·å–è‚¡ç¥¨åŸºç¡€ä¿¡æ¯"""
        logger.info("ğŸ“¥ è·å–è‚¡ç¥¨åŸºç¡€ä¿¡æ¯...")
        self.rate_limiter.wait_if_needed()
        df = self.pro.stock_basic(exchange='', list_status='L')
        
        conn = sqlite3.connect(DB_PATH)
        df.to_sql('stock_basic', conn, if_exists='replace', index=False)
        conn.close()
        
        logger.info(f"   å…±è·å– {len(df)} åªè‚¡ç¥¨")
        self._set_meta('stock_basic_count', str(len(df)))
        return df
    
    def fetch_index_components(self, index_code: str = INDEX_CODE) -> List[str]:
        """è·å–æŒ‡æ•°æˆåˆ†è‚¡å†å²ï¼ˆæŒ‰å­£åº¦é‡‡æ ·å‡å°‘è°ƒç”¨ï¼‰"""
        logger.info(f"ğŸ“¥ è·å–æŒ‡æ•° {index_code} æˆåˆ†è‚¡...")
        
        cached = self._get_meta(f'index_components_{index_code}')
        if cached:
            stock_list = cached.split(',')
            logger.info(f"   ä»ç¼“å­˜åŠ è½½ {len(stock_list)} åªæˆåˆ†è‚¡")
            return stock_list
        
        df_weights = []
        start_dt = datetime.strptime(START_DATE, "%Y%m%d")
        end_dt = datetime.strptime(END_DATE, "%Y%m%d")
        
        # æŒ‰å­£åº¦é‡‡æ ·ï¼ˆæ¯å¹´3ã€6ã€9ã€12æœˆï¼‰
        current = start_dt
        while current <= end_dt:
            # æ‰¾åˆ°æœ€è¿‘çš„å­£æœ«æ—¥
            quarter_end_month = ((current.month - 1) // 3 + 1) * 3
            if current.month == quarter_end_month:
                trade_date = current.strftime("%Y%m%d")
            else:
                next_quarter = current.replace(day=1)
                if quarter_end_month > 12:
                    next_quarter = next_quarter.replace(year=current.year+1, month=3)
                else:
                    next_quarter = next_quarter.replace(month=quarter_end_month+1)
                last_day = next_quarter - timedelta(days=1)
                trade_date = last_day.strftime("%Y%m%d")
            
            try:
                self.rate_limiter.wait_if_needed()
                df = self.pro.index_weight(index_code=index_code, trade_date=trade_date)
                if not df.empty:
                    df_weights.append(df)
                    logger.info(f"   {trade_date}: {len(df)} åªæˆåˆ†è‚¡")
            except Exception as e:
                logger.warning(f"   {trade_date}: è·å–å¤±è´¥ - {e}")
            
            # è·³åˆ°ä¸‹ä¸ªå­£åº¦
            if quarter_end_month == 12:
                current = current.replace(year=current.year+1, month=3, day=31)
            else:
                current = current.replace(month=quarter_end_month+3, day=1)
        
        if df_weights:
            df_all = pd.concat(df_weights, ignore_index=True)
            conn = sqlite3.connect(DB_PATH)
            df_all.to_sql('index_weight', conn, if_exists='replace', index=False)
            conn.close()
            
            all_stocks = sorted(df_all['con_code'].unique().tolist())
            self._set_meta(f'index_components_{index_code}', ','.join(all_stocks))
            logger.info(f"âœ… å…±è·å– {len(all_stocks)} åªä¸åŒçš„æˆåˆ†è‚¡")
            return all_stocks
        else:
            logger.error("âš ï¸ æœªè·å–åˆ°æˆåˆ†è‚¡æ•°æ®")
            return []
    
    def fetch_daily_price_batch(self, trade_date: str) -> Optional[pd.DataFrame]:
        """æ‰¹é‡è·å–å•æ—¥æ‰€æœ‰è‚¡ç¥¨æ—¥çº¿æ•°æ®ï¼ˆé«˜æ•ˆï¼‰"""
        try:
            self.rate_limiter.wait_if_needed()
            df = self.pro.daily(trade_date=trade_date)
            return df if not df.empty else None
        except Exception as e:
            logger.warning(f"   è·å– {trade_date} æ—¥çº¿æ•°æ®å¤±è´¥: {e}")
            return None
    
    def fetch_adj_factor_batch(self, trade_date: str) -> Optional[pd.DataFrame]:
        """æ‰¹é‡è·å–å•æ—¥å¤æƒå› å­"""
        try:
            self.rate_limiter.wait_if_needed()
            df = self.pro.adj_factor(trade_date=trade_date)
            return df if not df.empty else None
        except Exception as e:
            logger.warning(f"   è·å– {trade_date} å¤æƒå› å­å¤±è´¥: {e}")
            return None
    
    def fetch_daily_basic_batch(self, trade_date: str) -> Optional[pd.DataFrame]:
        """æ‰¹é‡è·å–å•æ—¥æ¯æ—¥æŒ‡æ ‡"""
        try:
            self.rate_limiter.wait_if_needed()
            df = self.pro.daily_basic(trade_date=trade_date)
            return df if not df.empty else None
        except Exception as e:
            logger.warning(f"   è·å– {trade_date} æ¯æ—¥æŒ‡æ ‡å¤±è´¥: {e}")
            return None
    
    def get_trade_dates(self) -> List[str]:
        """è·å–äº¤æ˜“æ—¥åˆ—è¡¨"""
        self.rate_limiter.wait_if_needed()
        df = self.pro.trade_cal(exchange='', start_date=START_DATE, end_date=END_DATE, is_open='1')
        return df['cal_date'].tolist()
    
    def fetch_all_data_by_date(self, stock_list: List[str]):
        """
        æŒ‰æ—¥æœŸæ‰¹é‡è·å–æ‰€æœ‰æ•°æ®ï¼ˆé«˜æ•ˆæ¨¡å¼ï¼‰
        
        Args:
            stock_list: è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼ˆç”¨äºè¿‡æ»¤ï¼‰
        """
        stock_set = set(stock_list)
        
        # è·å–äº¤æ˜“æ—¥åˆ—è¡¨
        logger.info("ğŸ“… è·å–äº¤æ˜“æ—¥åˆ—è¡¨...")
        trade_dates = self.get_trade_dates()
        logger.info(f"   å…± {len(trade_dates)} ä¸ªäº¤æ˜“æ—¥")
        
        # æ£€æŸ¥æ–­ç‚¹
        last_date = self._get_meta('last_fetched_date')
        if last_date:
            trade_dates = [d for d in trade_dates if d > last_date]
            logger.info(f"   ä»æ–­ç‚¹ {last_date} ç»§ç»­ï¼Œå‰©ä½™ {len(trade_dates)} å¤©")
        
        conn = sqlite3.connect(DB_PATH)
        
        for i, trade_date in enumerate(tqdm(trade_dates, desc="è·å–æ•°æ®")):
            # æ‰¹é‡è·å–æ—¥çº¿
            df_daily = self.fetch_daily_price_batch(trade_date)
            if df_daily is not None:
                df_daily = df_daily[df_daily['ts_code'].isin(stock_set)]
                df_daily.to_sql('daily_price', conn, if_exists='append', index=False)
            
            # æ‰¹é‡è·å–å¤æƒå› å­
            df_adj = self.fetch_adj_factor_batch(trade_date)
            if df_adj is not None:
                df_adj = df_adj[df_adj['ts_code'].isin(stock_set)]
                df_adj.to_sql('adj_factor', conn, if_exists='append', index=False)
            
            # æ‰¹é‡è·å–æ¯æ—¥æŒ‡æ ‡ï¼ˆ2000ç§¯åˆ†æ”¯æŒï¼‰
            df_basic = self.fetch_daily_basic_batch(trade_date)
            if df_basic is not None:
                # é€‰æ‹©å…³é”®å­—æ®µ
                cols = ['ts_code', 'trade_date', 'turnover_rate', 'turnover_rate_f',
                       'pe', 'pe_ttm', 'pb', 'total_mv', 'circ_mv']
                df_basic = df_basic[df_basic['ts_code'].isin(stock_set)]
                df_basic = df_basic[[c for c in cols if c in df_basic.columns]]
                df_basic.to_sql('daily_basic', conn, if_exists='append', index=False)
            
            # æ¯ 10 å¤©ä¿å­˜ä¸€æ¬¡æ–­ç‚¹
            if (i + 1) % 10 == 0:
                self._set_meta('last_fetched_date', trade_date)
                logger.info(f"   å·²ä¿å­˜æ–­ç‚¹: {trade_date}")
        
        conn.close()
        self._set_meta('last_fetched_date', trade_dates[-1] if trade_dates else '')
        logger.info("âœ… æ•°æ®è·å–å®Œæˆï¼")


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸš€ Tushare æ•°æ®è·å–å·¥å…·ï¼ˆä¼˜åŒ–ç‰ˆï¼‰")
    print("=" * 60)
    
    fetcher = TushareDataFetcherOptimized()
    
    # 1. è·å–è‚¡ç¥¨åŸºç¡€ä¿¡æ¯
    fetcher.fetch_stock_basic()
    
    # 2. è·å–æŒ‡æ•°æˆåˆ†è‚¡
    stock_list = fetcher.fetch_index_components(INDEX_CODE)
    
    if not stock_list:
        print("âŒ æœªè·å–åˆ°æˆåˆ†è‚¡ï¼Œé€€å‡º")
        return
    
    # 3. æŒ‰æ—¥æœŸæ‰¹é‡è·å–æ•°æ®ï¼ˆé«˜æ•ˆï¼‰
    fetcher.fetch_all_data_by_date(stock_list)
    
    print("\n" + "=" * 60)
    print("âœ… æ•°æ®è·å–å®Œæˆï¼")
    print(f"ğŸ“ æ•°æ®å­˜å‚¨åœ¨: {DB_PATH}")
    print("=" * 60)


if __name__ == "__main__":
    main()
