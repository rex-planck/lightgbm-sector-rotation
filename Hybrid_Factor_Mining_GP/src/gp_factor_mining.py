"""
é—ä¼ è§„åˆ’å› å­æŒ–æ˜æ¨¡å—
ä½¿ç”¨ gplearn è‡ªåŠ¨æŒ–æ˜ Alpha å› å­
"""
import numpy as np
import pandas as pd
from gplearn.genetic import SymbolicRegressor
from gplearn.functions import make_function
from sklearn.model_selection import train_test_split
import pickle
import os
from typing import List, Dict, Tuple
from tqdm import tqdm

from config import (
    GP_CONFIG, FACTOR_OUTPUT_DIR, LABEL_COL,
    BASE_FEATURES
)
from data_loader import DataLoader


# ==================== è‡ªå®šä¹‰å‡½æ•° ====================
def rank(x):
    """æˆªé¢æ’åï¼ˆæ›¿ä»£ alphalens çš„ rankï¼‰"""
    return pd.Series(x).rank(pct=True).values if len(x) > 1 else np.zeros_like(x)

def ts_rank(x, window=10):
    """æ—¶åºæ’å"""
    if len(x) < window:
        return np.zeros_like(x)
    s = pd.Series(x)
    return s.rolling(window).apply(lambda y: y.rank(pct=True).iloc[-1] if len(y) == window else 0, raw=False).values

def ts_mean(x, window=10):
    """æ—¶åºå‡å€¼"""
    return pd.Series(x).rolling(window).mean().values

def ts_std(x, window=10):
    """æ—¶åºæ ‡å‡†å·®"""
    return pd.Series(x).rolling(window).std().values

def ts_max(x, window=10):
    """æ—¶åºæœ€å¤§å€¼"""
    return pd.Series(x).rolling(window).max().values

def ts_min(x, window=10):
    """æ—¶åºæœ€å°å€¼"""
    return pd.Series(x).rolling(window).min().values

def ts_delta(x, window=10):
    """æ—¶åºå·®åˆ†"""
    return pd.Series(x).diff(window).values

def ts_corr(x, y, window=10):
    """æ—¶åºç›¸å…³æ€§"""
    return pd.Series(x).rolling(window).corr(pd.Series(y)).values

# åŒ…è£…ä¸º gplearn å‡½æ•°
rank_function = make_function(function=rank, name='rank', arity=1)
ts_mean_function = make_function(function=ts_mean, name='ts_mean', arity=1)
ts_std_function = make_function(function=ts_std, name='ts_std', arity=1)
ts_max_function = make_function(function=ts_max, name='ts_max', arity=1)
ts_min_function = make_function(function=ts_min, name='ts_min', arity=1)
ts_delta_function = make_function(function=ts_delta, name='ts_delta', arity=1)


class GPFactorMiner:
    """GP å› å­æŒ–æ˜å™¨"""
    
    def __init__(self, config: Dict = None):
        """
        åˆå§‹åŒ–
        
        Args:
            config: GP é…ç½®å‚æ•°
        """
        self.config = config or GP_CONFIG
        self.mined_factors = []  # å­˜å‚¨æŒ–æ˜å‡ºçš„å› å­
        self.factor_programs = []  # å­˜å‚¨å› å­ç¨‹åºï¼ˆå¯å¤ç°ï¼‰
    
    def calculate_ic(self, factor_values: np.ndarray, labels: np.ndarray) -> float:
        """
        è®¡ç®— Rank IC
        
        Args:
            factor_values: å› å­å€¼
            labels: æ ‡ç­¾ï¼ˆæœªæ¥æ”¶ç›Šç‡ï¼‰
            
        Returns:
            Rank IC å€¼
        """
        # æ¸…æ´—æ•°æ®
        mask = ~(np.isnan(factor_values) | np.isnan(labels) | 
                 np.isinf(factor_values) | np.isinf(labels))
        
        if mask.sum() < 10:
            return 0.0
        
        f = factor_values[mask]
        l = labels[mask]
        
        # è®¡ç®— Rank IC
        f_rank = pd.Series(f).rank()
        l_rank = pd.Series(l).rank()
        
        ic = np.corrcoef(f_rank, l_rank)[0, 1]
        return ic if not np.isnan(ic) else 0.0
    
    def mine_factor_single_day(self, X: pd.DataFrame, y: np.ndarray) -> Tuple[str, float]:
        """
        å¯¹å•æ—¥æˆªé¢æ•°æ®è¿›è¡Œå› å­æŒ–æ˜
        
        Args:
            X: ç‰¹å¾æ•°æ® (n_stocks, n_features)
            y: æ ‡ç­¾ (n_stocks,)
            
        Returns:
            (æœ€ä½³å› å­ç¨‹åºå­—ç¬¦ä¸², ICå€¼)
        """
        # è‡ªå®šä¹‰é€‚åº”åº¦å‡½æ•°
        def _rank_ic_scorer(estimator, X, y):
            y_pred = estimator.predict(X)
            return abs(self.calculate_ic(y_pred, y))
        
        # åˆ›å»º GP æ¨¡å‹
        est_gp = SymbolicRegressor(
            population_size=self.config['population_size'],
            generations=self.config['generations'],
            tournament_size=self.config['tournament_size'],
            stopping_criteria=self.config['stopping_criteria'],
            p_crossover=self.config['p_crossover'],
            p_subtree_mutation=self.config['p_subtree_mutation'],
            p_hoist_mutation=self.config['p_hoist_mutation'],
            p_point_mutation=self.config['p_point_mutation'],
            max_samples=self.config['max_samples'],
            parsimony_coefficient=self.config['parsimony_coefficient'],
            random_state=np.random.randint(0, 10000),
            function_set=self.config['function_set'],
            metric=_rank_ic_scorer,
            verbose=0
        )
        
        try:
            est_gp.fit(X, y)
            best_program = est_gp._program
            best_ic = best_program.raw_fitness_
            return str(best_program), best_ic
        except Exception as e:
            return None, 0.0
    
    def mine_factors_cross_section(self, df: pd.DataFrame, 
                                   feature_cols: List[str],
                                   n_days: int = 50) -> pd.DataFrame:
        """
        æˆªé¢å› å­æŒ–æ˜ï¼ˆæ¯å¤©ç‹¬ç«‹æŒ–æ˜ï¼‰
        
        Args:
            df: æ•°æ® DataFrame
            feature_cols: ç”¨äºæŒ–æ˜çš„ç‰¹å¾åˆ—
            n_days: é‡‡æ ·çš„å¤©æ•°
            
        Returns:
            æŒ–æ˜å‡ºçš„å› å­ DataFrame
        """
        print(f"ğŸ§¬ å¼€å§‹æˆªé¢å› å­æŒ–æ˜ï¼ˆé‡‡æ · {n_days} å¤©ï¼‰...")
        
        # éšæœºé‡‡æ ·äº¤æ˜“æ—¥
        trade_dates = df['trade_date'].unique()
        if len(trade_dates) > n_days:
            sampled_dates = np.random.choice(trade_dates, n_days, replace=False)
        else:
            sampled_dates = trade_dates
        
        factor_results = []
        
        for date in tqdm(sampled_dates, desc="æŒ–æ˜å› å­"):
            day_data = df[df['trade_date'] == date]
            
            if len(day_data) < 50:  # è‚¡ç¥¨æ•°é‡å¤ªå°‘åˆ™è·³è¿‡
                continue
            
            X = day_data[feature_cols].values
            y = day_data[LABEL_COL].values
            
            # æ¸…æ´—æ•°æ®
            mask = ~(np.isnan(X).any(axis=1) | np.isnan(y))
            X, y = X[mask], y[mask]
            
            if len(X) < 50:
                continue
            
            # æŒ–æ˜å› å­
            program_str, ic = self.mine_factor_single_day(
                pd.DataFrame(X, columns=feature_cols), y
            )
            
            if program_str and ic > self.config['min_ic_threshold']:
                factor_results.append({
                    'date': date,
                    'program': program_str,
                    'ic': ic,
                    'n_stocks': len(X)
                })
        
        df_factors = pd.DataFrame(factor_results)
        print(f"âœ… æŒ–æ˜å‡º {len(df_factors)} ä¸ªå€™é€‰å› å­")
        
        return df_factors
    
    def deduplicate_factors(self, df_factors: pd.DataFrame, 
                           df_full: pd.DataFrame,
                           feature_cols: List[str],
                           top_n: int = 50) -> pd.DataFrame:
        """
        å› å­å»é‡ï¼šåŸºäºå…¨æ ·æœ¬ IC å’Œç›¸å…³æ€§ç­›é€‰
        
        Args:
            df_factors: å€™é€‰å› å­ DataFrame
            df_full: å®Œæ•´æ•°æ®
            feature_cols: ç‰¹å¾åˆ—
            top_n: æœ€ç»ˆä¿ç•™çš„å› å­æ•°
            
        Returns:
            ç­›é€‰åçš„å› å­ DataFrame
        """
        print(f"ğŸ”„ å¼€å§‹å› å­å»é‡å’Œç­›é€‰...")
        
        # æŒ‰ç¨‹åºåˆ†ç»„ï¼Œé€‰æ‹©å‡ºç°é¢‘ç‡é«˜ä¸” IC é«˜çš„
        program_stats = df_factors.groupby('program').agg({
            'ic': ['mean', 'std', 'count']
        }).reset_index()
        program_stats.columns = ['program', 'ic_mean', 'ic_std', 'frequency']
        program_stats['score'] = program_stats['ic_mean'] * np.log1p(program_stats['frequency'])
        
        # é€‰æ‹© Top N
        top_programs = program_stats.nlargest(min(top_n * 2, len(program_stats)), 'score')
        
        print(f"   é€‰æ‹© {len(top_programs)} ä¸ªé«˜é¢‘é«˜ IC å› å­è¿›è¡Œå…¨æ ·æœ¬éªŒè¯")
        
        # å…¨æ ·æœ¬è®¡ç®— IC
        final_factors = []
        for _, row in tqdm(top_programs.iterrows(), desc="å…¨æ ·æœ¬éªŒè¯"):
            program_str = row['program']
            
            # è¿™é‡Œç®€åŒ–å¤„ç†ï¼šå‡è®¾å¯ä»¥é€šè¿‡ç¨‹åºå­—ç¬¦ä¸²å¤ç°å› å­å€¼
            # å®é™…åº”ç”¨ä¸­éœ€è¦å°†ç¨‹åºè½¬æ¢ä¸ºå¯æ‰§è¡Œä»£ç 
            # æš‚æ—¶ä½¿ç”¨ IC å‡å€¼ä½œä¸ºå› å­å€¼ä»£ç†
            
            final_factors.append({
                'program': program_str,
                'ic_mean': row['ic_mean'],
                'ic_std': row['ic_std'],
                'frequency': row['frequency'],
                'score': row['score']
            })
        
        df_final = pd.DataFrame(final_factors)
        df_final = df_final.nlargest(top_n, 'score')
        
        print(f"âœ… æœ€ç»ˆç­›é€‰å‡º {len(df_final)} ä¸ªé«˜è´¨é‡å› å­")
        
        return df_final
    
    def save_factors(self, df_factors: pd.DataFrame, filename: str = "mined_factors.csv"):
        """ä¿å­˜æŒ–æ˜çš„å› å­"""
        output_path = os.path.join(FACTOR_OUTPUT_DIR, filename)
        df_factors.to_csv(output_path, index=False)
        print(f"ğŸ’¾ å› å­å·²ä¿å­˜åˆ°: {output_path}")


def main():
    """ä¸»å‡½æ•°ï¼šè¿è¡Œå› å­æŒ–æ˜æµç¨‹"""
    print("=" * 60)
    print("ğŸš€ GP å› å­æŒ–æ˜ç³»ç»Ÿ")
    print("=" * 60)
    
    # 1. åŠ è½½æ•°æ®
    loader = DataLoader()
    df_raw = loader.load_all_data()
    df_features = loader.prepare_features(df_raw)
    df_labeled = loader.prepare_labels(df_features)
    
    # 2. é€‰æ‹©ç”¨äºæŒ–æ˜çš„ç‰¹å¾
    feature_cols = [
        'open', 'high', 'low', 'close', 'vol',
        'turnover_rate', 'pe', 'pb',
        'returns_1d', 'returns_5d', 'returns_20d',
        'volatility_20d', 'volume_ratio', 'price_position',
        'rsi_14', 'macd'
    ]
    
    # åªä¿ç•™å­˜åœ¨çš„åˆ—
    feature_cols = [c for c in feature_cols if c in df_labeled.columns]
    print(f"\nğŸ“‹ ç”¨äºå› å­æŒ–æ˜çš„ç‰¹å¾: {feature_cols}")
    
    # 3. ä½¿ç”¨è®­ç»ƒé›†æŒ–æ˜å› å­
    train_df = df_labeled[df_labeled['trade_date'] <= '20211231']
    
    # 4. åˆ›å»ºæŒ–æ˜å™¨å¹¶è¿è¡Œ
    miner = GPFactorMiner()
    
    # æˆªé¢æŒ–æ˜
    df_candidate_factors = miner.mine_factors_cross_section(
        train_df, feature_cols, n_days=50
    )
    
    # å»é‡ç­›é€‰
    df_final_factors = miner.deduplicate_factors(
        df_candidate_factors, train_df, feature_cols, top_n=GP_CONFIG['n_factors']
    )
    
    # ä¿å­˜ç»“æœ
    miner.save_factors(df_final_factors)
    
    # æ‰“å° Top 10 å› å­
    print("\nğŸ† Top 10 æŒ–æ˜å‡ºçš„å› å­:")
    print(df_final_factors.head(10)[['program', 'ic_mean', 'frequency']].to_string())
    
    loader.close()
    
    print("\n" + "=" * 60)
    print("âœ… å› å­æŒ–æ˜å®Œæˆï¼")
    print("=" * 60)


if __name__ == "__main__":
    main()
