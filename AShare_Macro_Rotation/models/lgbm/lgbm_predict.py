import pandas as pd
import numpy as np
import lightgbm as lgb
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import accuracy_score, roc_auc_score
import matplotlib.pyplot as plt
import os

# === é…ç½®åŒº ===
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))

# å…³é”®ä¿®æ”¹ï¼šå› ä¸ºæ–‡ä»¶åœ¨ models/lgbm/ ä¸‹ï¼Œéœ€è¦å¾€ä¸Šé€€ä¸¤å±‚æ‰èƒ½å›åˆ°é¡¹ç›®æ ¹ç›®å½•
# level 1: models/lgbm -> models
# level 2: models -> AShare_Macro_Rotation (æ ¹ç›®å½•)
PROJECT_ROOT = os.path.dirname(os.path.dirname(CURRENT_DIR))

PROCESSED_PATH = os.path.join(PROJECT_ROOT, 'data', 'processed')
RAW_PATH = os.path.join(PROJECT_ROOT, 'data', 'raw')

# æ‰“å°ä¸€ä¸‹è·¯å¾„ï¼Œç¡®ä¿æ²¡é”™
print(f"ğŸ“‚ æ•°æ®è¯»å–è·¯å¾„: {RAW_PATH}")


def load_data(sector_name="åŠå¯¼ä½“"):
    # 1. åŠ è½½è¡Œä¸šæ•°æ®
    df_sector = pd.read_csv(os.path.join(RAW_PATH, f'sector_{sector_name}.csv'))
    # ç®€å•çš„åˆ—åæ¸…æ´—
    col_map = {c: 'date' for c in df_sector.columns if 'æ—¥æœŸ' in c}
    col_map.update({c: 'close' for c in df_sector.columns if 'æ”¶ç›˜' in c})
    col_map.update({c: 'open' for c in df_sector.columns if 'å¼€ç›˜' in c})
    col_map.update({c: 'high' for c in df_sector.columns if 'æœ€é«˜' in c})
    col_map.update({c: 'low' for c in df_sector.columns if 'æœ€ä½' in c})
    col_map.update({c: 'vol' for c in df_sector.columns if 'æˆäº¤é‡' in c})

    df_sector = df_sector.rename(columns=col_map)
    df_sector['date'] = pd.to_datetime(df_sector['date'])

    # 2. åŠ è½½ HMM å®è§‚çŠ¶æ€
    df_hmm = pd.read_csv(os.path.join(PROCESSED_PATH, 'hmm_signals.csv'))
    df_hmm['date'] = pd.to_datetime(df_hmm['date'])

    # åˆå¹¶
    df = pd.merge(df_sector, df_hmm[['date', 'hidden_state', 'Liquidity_Diff']], on='date', how='inner')
    df = df.sort_values('date').reset_index(drop=True)
    return df


def feature_engineering(df):
    """
    æ„å»ºç¬¦åˆ LightGBM è¾“å…¥çš„ç‰¹å¾ (JD: ç‰¹å¾å·¥ç¨‹)
    """
    # 1. åŸºç¡€é‡ä»·ç‰¹å¾
    df['ret_1'] = df['close'].pct_change()
    df['ret_5'] = df['close'].pct_change(5)
    df['vol_change'] = df['vol'].pct_change()

    # 2. æ³¢åŠ¨ç‡ç‰¹å¾
    df['std_20'] = df['ret_1'].rolling(20).std()

    # 3. æŠ€æœ¯æŒ‡æ ‡ (æ‰‹åŠ¨è®¡ç®— RSI, å…å»å®‰è£… TA-Lib çš„éº»çƒ¦)
    delta = df['close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    df['RSI'] = 100 - (100 / (1 + gain / loss))

    # 4. å®è§‚äº¤äº’ç‰¹å¾ (å…³é”®åˆ›æ–°ç‚¹!)
    # é€»è¾‘: åœ¨ç‰›å¸‚(State 2)ä¸­ï¼ŒRSIè¶…ä¹°å¯èƒ½ä¸æ˜¯é¡¶ï¼›åœ¨ç†Šå¸‚(State 0)ä¸­ï¼ŒRSIè¶…å–å¯èƒ½ä¸æ˜¯åº•
    df['Macro_RSI_Interact'] = df['hidden_state'] * df['RSI']

    # 5. æ ‡ç­¾ (Label): é¢„æµ‹æ˜å¤©æ¶¨(1)è¿˜æ˜¯è·Œ(0)
    # Aè‚¡å®åŠ¡: é¢„æµ‹æ”¶ç›Šç‡ > 0.1% (æ‰£é™¤æ‰‹ç»­è´¹)
    df['target'] = (df['close'].shift(-1) / df['close'] - 1 > 0.001).astype(int)

    # å»é™¤ç©ºå€¼
    df = df.dropna()
    return df


def train_lgbm(df):
    """
    ä½¿ç”¨ LightGBM è¿›è¡Œæ»šåŠ¨è®­ç»ƒ (Walk-Forward)
    """
    print("ğŸ¤– æ­£åœ¨è®­ç»ƒ LightGBM æ¨¡å‹...")

    features = ['ret_1', 'ret_5', 'vol_change', 'std_20', 'RSI', 'hidden_state', 'Liquidity_Diff', 'Macro_RSI_Interact']
    target = 'target'

    # æ—¶é—´åºåˆ—åˆ†å‰² (é˜²æ­¢æœªæ¥å‡½æ•°)
    # ä»¥å‰ 80% åšè®­ç»ƒï¼Œå 20% åšæµ‹è¯•
    split_idx = int(len(df) * 0.8)
    train_df = df.iloc[:split_idx]
    test_df = df.iloc[split_idx:]

    print(f"   è®­ç»ƒé›†: {len(train_df)} å¤© | æµ‹è¯•é›†: {len(test_df)} å¤©")

    # åˆ›å»º LGB æ•°æ®é›†
    lgb_train = lgb.Dataset(train_df[features], label=train_df[target])
    lgb_eval = lgb.Dataset(test_df[features], label=test_df[target], reference=lgb_train)

    # å‚æ•° (é’ˆå¯¹é‡‘èæ—¶åºå¾®è°ƒ)
    params = {
        'objective': 'binary',
        'metric': 'auc',
        'boosting_type': 'gbdt',
        'num_leaves': 31,
        'learning_rate': 0.05,
        'feature_fraction': 0.9
    }

    model = lgb.train(
        params,
        lgb_train,
        num_boost_round=1000,
        valid_sets=[lgb_train, lgb_eval],
        callbacks=[lgb.early_stopping(stopping_rounds=50), lgb.log_evaluation(100)]
    )

    # é¢„æµ‹
    y_pred_prob = model.predict(test_df[features])
    y_pred_class = (y_pred_prob > 0.52).astype(int)  # é˜ˆå€¼è®¾é«˜ä¸€ç‚¹(0.52)æé«˜èƒœç‡

    # è¯„ä¼°
    acc = accuracy_score(test_df[target], y_pred_class)
    auc = roc_auc_score(test_df[target], y_pred_prob)

    print("-" * 30)
    print(f"   âœ… é¢„æµ‹å‡†ç¡®ç‡ (Accuracy): {acc:.2%}")
    print(f"   âœ… AUC å¾—åˆ†: {auc:.4f}")

    # ç‰¹å¾é‡è¦æ€§
    print("\n   ğŸ” ç‰¹å¾é‡è¦æ€§æ’åº:")
    importance = pd.DataFrame({
        'Feature': features,
        'Importance': model.feature_importance()
    }).sort_values('Importance', ascending=False)
    print(importance)

    return model, importance


if __name__ == "__main__":
    df_raw = load_data("åŠå¯¼ä½“")
    df_feat = feature_engineering(df_raw)
    model, imp = train_lgbm(df_feat)