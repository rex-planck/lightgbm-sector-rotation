diff --git a/python_program/05_model_gru.py b/python_program/05_model_gru.py
index a28ea27..01539b5 100644
--- a/python_program/05_model_gru.py
+++ b/python_program/05_model_gru.py
@@ -2,147 +2,173 @@ import qlib
 from qlib.constant import REG_CN
 from qlib.utils import init_instance_by_config
 from qlib.workflow import R
-# ç›´æ¥ä½¿ç”¨å®˜æ–¹ç±»ï¼Œä¸æè‡ªå®šä¹‰ç»§æ‰¿äº†
-from qlib.data.dataset.handler import DataHandlerLP
+import torch
+import torch.nn as nn
+import torch.optim as optim
 import pandas as pd
+import numpy as np
 import os
 
 # 1. åˆå§‹åŒ–
 provider_uri = r"E:\Quant_program\Qlib-Cache\cn_data"
 qlib.init(provider_uri=provider_uri, region=REG_CN)
 
-# 2. å®šä¹‰è‡ªå®šä¹‰å› å­ (çº¯å…¬å¼åˆ—è¡¨)
-custom_factors = [
-    "( $close - Mean($close, 5) ) / Mean($close, 5)",  # 5æ—¥ä¹–ç¦»
-    "$volume / Mean($volume, 20)",  # é‡æ¯”
-    "Std($close, 20) / $close",  # æ³¢åŠ¨ç‡
-    "($open - Ref($close, 1)) / Ref($close, 1)",  # éš”å¤œè·³ç©º
-    "($close - $open) / $open"  # æ—¥å†…åŠ›åº¦
-]
 
-# 3. é…ç½®å·¥ä½œæµ
+# 2. å®šä¹‰ä¸€ä¸ªçº¯ç²¹çš„ PyTorch GRU æ¨¡å‹
+# è¿™å°±æ˜¯é¢è¯•å®˜æœ€æƒ³çœ‹åˆ°çš„ä¸œè¥¿ï¼šä½ æ‡‚ç½‘ç»œç»“æ„
+class SimpleGRU(nn.Module):
+    def __init__(self, input_size, hidden_size=64, num_layers=2):
+        super(SimpleGRU, self).__init__()
+        # GRU å±‚: æå–æ—¶åºç‰¹å¾
+        self.gru = nn.GRU(
+            input_size=input_size,
+            hidden_size=hidden_size,
+            num_layers=num_layers,
+            batch_first=True
+        )
+        # å…¨è¿æ¥å±‚: è¾“å‡ºé¢„æµ‹å€¼
+        self.fc = nn.Linear(hidden_size, 1)
+
+    def forward(self, x):
+        # x shape: (batch, seq_len, features)
+        out, _ = self.gru(x)
+        # å–æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å‡º: out[:, -1, :]
+        out = self.fc(out[:, -1, :])
+        return out.squeeze()  # å˜æˆä¸€ç»´æ•°ç»„
+
+
+# 3. å‡†å¤‡æ•°æ®é…ç½®
 market = "csi300"
 benchmark = "SH000300"
-FIT_START = "2018-01-01"
-FIT_END = "2020-12-31"
+d_feat = 158  # Alpha158 çš„ç‰¹å¾æ•°é‡
 
 data_handler_config = {
-    "start_time": "2018-01-01",
+    "start_time": "2015-01-01",
     "end_time": "2022-12-31",
-
-    # âš ï¸ã€å…³é”®ä¿®æ”¹ã€‘è¿™é‡Œåƒä¸‡ä¸è¦å†™ fit_start_timeï¼
-    # å¦‚æœå†™äº†ï¼ŒDataHandlerLP å°±ä¼šæŠ¥é”™ "unexpected argument"ã€‚
-    # "fit_start_time": FIT_START,  <-- åˆ é™¤
-    # "fit_end_time": FIT_END,      <-- åˆ é™¤
-
+    "fit_start_time": "2015-01-01",
+    "fit_end_time": "2020-12-31",
     "instruments": market,
-
-    # æ•°æ®åŠ è½½é…ç½®
-    "data_loader": {
-        "class": "QlibDataLoader",
-        "module_path": "qlib.data.dataset.loader",
-        "kwargs": {
-            "config": {
-                "feature": custom_factors,
-                "label": ["Ref($close, -5) / $close - 1"],
-            },
-        },
-    },
-
-    # ğŸ”¥ğŸ”¥ğŸ”¥ã€å…³é”®ä¿®æ”¹ã€‘åœ¨è¿™é‡Œæ˜¾å¼æ³¨å…¥æ—¶é—´å‚æ•° ğŸ”¥ğŸ”¥ğŸ”¥
-    # è¿™æ ·åº•å±‚å¤„ç†å™¨èƒ½æ‹¿åˆ°å‚æ•°ï¼Œè€Œä¸Šå±‚ Handler åˆä¸ä¼šæŠ¥é”™
     "infer_processors": [
-        {
-            "class": "RobustZScoreNorm",
-            "kwargs": {
-                "fields_group": "feature",
-                "clip_outlier": True,
-                "fit_start_time": FIT_START,  # ğŸ‘ˆ è¿™é‡Œå¿…é¡»ç»™
-                "fit_end_time": FIT_END  # ğŸ‘ˆ è¿™é‡Œå¿…é¡»ç»™
-            }
-        },
+        {"class": "RobustZScoreNorm", "kwargs": {"fields_group": "feature", "clip_outlier": True}},
         {"class": "Fillna", "kwargs": {"fields_group": "feature"}},
     ],
     "learn_processors": [
         {"class": "DropnaLabel"},
-        {
-            "class": "CSRankNorm",
-            "kwargs": {
-                "fields_group": "label",
-                "fit_start_time": FIT_START,  # ğŸ‘ˆ è¿™é‡Œå¿…é¡»ç»™
-                "fit_end_time": FIT_END  # ğŸ‘ˆ è¿™é‡Œå¿…é¡»ç»™
-            }
-        },
+        {"class": "CSRankNorm", "kwargs": {"fields_group": "label"}},
     ],
+    "label": ["Ref($close, -5) / $close - 1"],
 }
 
-task = {
-    "model": {
-        "class": "LGBModel",
-        "module_path": "qlib.contrib.model.gbdt",
-        "kwargs": {
-            "loss": "mse",
-            "colsample_bytree": 0.8879,
-            "learning_rate": 0.0421,
-            "subsample": 0.8789,
-            "lambda_l1": 205.6999,
-            "lambda_l2": 580.9768,
-            "max_depth": 8,
-            "num_leaves": 210,
-            "num_threads": 20,
+# ä½¿ç”¨ TSDatasetH ç”Ÿæˆæ—¶åºæ•°æ®
+dataset_config = {
+    "class": "TSDatasetH",
+    "module_path": "qlib.data.dataset",
+    "kwargs": {
+        "handler": {
+            "class": "Alpha158",
+            "module_path": "qlib.contrib.data.handler",
+            "kwargs": data_handler_config,
         },
-    },
-    "dataset": {
-        "class": "DatasetH",
-        "module_path": "qlib.data.dataset",
-        "kwargs": {
-            "handler": {
-                # ç›´æ¥ç”¨å®˜æ–¹ç±»ï¼Œé€šè¿‡é…ç½®è§£å†³é—®é¢˜
-                "class": "DataHandlerLP",
-                "module_path": "qlib.data.dataset.handler",
-                "kwargs": data_handler_config,
-            },
-            "segments": {
-                "train": (FIT_START, FIT_END),
-                "valid": ("2021-01-01", "2021-12-31"),
-                "test": ("2022-01-01", "2022-12-31"),
-            },
+        "segments": {
+            "train": ("2015-01-01", "2020-12-31"),
+            "valid": ("2021-01-01", "2021-12-31"),
+            "test": ("2022-01-01", "2022-12-31"),
         },
+        "step_len": 20,  # å¾€å›çœ‹ 20 å¤©
     },
 }
 
+
+# 4. æ‰‹å†™è®­ç»ƒæµç¨‹ (The Hardcore Part)
+def run_custom_training():
+    with R.start(experiment_name="custom_gru_training"):
+        print("ğŸ› ï¸ åˆå§‹åŒ–æ•°æ®å¼•æ“...")
+        dataset = init_instance_by_config(dataset_config)
+
+        # è·å– DataLoader (TSDatasetH è‡ªåŠ¨å¸®æˆ‘ä»¬åˆ‡åˆ† Batch)
+        # train_loader æ¯æ¬¡ä¼šåå‡º (data, label)
+        train_loader = dataset.prepare("train", col_set=["feature", "label"], data_key="core")
+        valid_loader = dataset.prepare("valid", col_set=["feature", "label"], data_key="core")
+        test_loader = dataset.prepare("test", col_set=["feature", "label"], data_key="core")
+
+        # å®ä¾‹åŒ–æ¨¡å‹
+        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
+        print(f"ğŸš€ ä½¿ç”¨è®¾å¤‡: {device}")
+
+        model = SimpleGRU(input_size=158, hidden_size=64).to(device)
+        criterion = nn.MSELoss()
+        optimizer = optim.Adam(model.parameters(), lr=0.001)
+
+        print("\nğŸ”¥ å¼€å§‹æ‰‹å†™è®­ç»ƒå¾ªç¯ (Training Loop)...")
+        epochs = 5
+        for epoch in range(epochs):
+            model.train()
+            total_loss = 0
+            count = 0
+
+            # è¿­ä»£æ¯ä¸€æ‰¹æ•°æ®
+            for batch_idx, batch_data in enumerate(train_loader):
+                # è¿™é‡Œçš„ data æ˜¯ (Batch, 20, 158) çš„ 3D å¼ é‡
+                data = torch.tensor(batch_data[:, :, 0:-1], dtype=torch.float32).to(device)  # ç‰¹å¾
+                label = torch.tensor(batch_data[:, -1, -1], dtype=torch.float32).to(device)  # æ ‡ç­¾
+
+                optimizer.zero_grad()
+                output = model(data)
+                loss = criterion(output, label)
+                loss.backward()
+                optimizer.step()
+
+                total_loss += loss.item()
+                count += 1
+
+            print(f"   Epoch {epoch + 1}/{epochs} | Loss: {total_loss / count:.6f}")
+
+        print("\nğŸ”® å¼€å§‹é¢„æµ‹ (Inference)...")
+        model.eval()
+        preds = []
+        indices = []
+
+        with torch.no_grad():
+            for batch_idx, batch_data in enumerate(test_loader):
+                data = torch.tensor(batch_data[:, :, 0:-1], dtype=torch.float32).to(device)
+                output = model(data)
+                preds.append(output.cpu().numpy())
+
+                # Qlib çš„ loader æ¯”è¾ƒç‰¹æ®Šï¼Œè¿™é‡Œæˆ‘ä»¬éœ€è¦ä¸€ç‚¹æŠ€å·§æ¥è¿˜åŸç´¢å¼•
+                # ä¸ºäº†ç®€å•èµ·è§ï¼Œæˆ‘ä»¬ç›´æ¥è·å–åŸå§‹ DataFrame çš„ç´¢å¼•
+                # æ³¨æ„ï¼šè¿™é‡Œä¸ºäº†æ¼”ç¤ºï¼Œç®€åŒ–äº†å¯¹é½æ­¥éª¤ï¼Œå®æˆ˜ä¸­ä¼šæ›´å¤æ‚
+
+        # ç®€å•æ‹¼æ¥é¢„æµ‹ç»“æœ
+        all_preds = np.concatenate(preds)
+
+        # ä¸ºäº†è®¡ç®— ICï¼Œæˆ‘ä»¬é‡æ–°æ‹‰å– test æ•°æ®çš„ Label
+        # è¿™é‡Œç”¨ä¸€ä¸ªå°æŠ€å·§ï¼šç›´æ¥ä» dataset è·å–åŸå§‹ DataFrame
+        # TSDatasetH.handler è·å–çš„æ˜¯åº•å±‚ 2D æ•°æ®
+        df_test = dataset.prepare("test", col_set=["label"])
+
+        # æ³¨æ„ï¼šç”±äºæ—¶åºæ¨¡å‹æœ‰ step_len=20ï¼Œå‰19å¤©çš„æ•°æ®ä¼šè¢«åˆ‡æ‰
+        # æˆ‘ä»¬éœ€è¦å¯¹é½é•¿åº¦
+        if len(all_preds) != len(df_test):
+            print(f"âš ï¸ é•¿åº¦ä¸ä¸€è‡´: Preds {len(all_preds)} vs Labels {len(df_test)}")
+            # é€šå¸¸éœ€è¦å¯¹é½ç´¢å¼•ï¼Œè¿™é‡Œæˆ‘ä»¬å–ååŠæ®µï¼ˆå› ä¸º TSDatasetH ä¼šä»ç¬¬20å¤©å¼€å§‹åæ•°æ®ï¼‰
+            # è¿™æ˜¯ä¸€ä¸ªå¸¸è§çš„ Index Alignment é—®é¢˜
+            df_test_aligned = df_test.iloc[-len(all_preds):]
+            label_array = df_test_aligned.iloc[:, 0].values
+
+            # è®¡ç®— IC
+            df_res = pd.DataFrame({"pred": all_preds, "label": label_array})
+            ic = df_res.corr().iloc[0, 1]
+            rank_ic = df_res.rank().corr().iloc[0, 1]
+
+            print("-" * 50)
+            print(f"ğŸ“Š å®éªŒç»“æœ (Custom PyTorch Loop):")
+            print(f"   IC:      {ic:.4f}")
+            print(f"   Rank IC: {rank_ic:.4f}")
+            print("-" * 50)
+
+            if rank_ic > 0.02:
+                print("âœ… æˆåŠŸï¼æ‰‹å†™ç¥ç»ç½‘ç»œè·‘é€šäº†ï¼")
+
+
 if __name__ == "__main__":
-    with R.start(experiment_name="research_custom_factors"):
-        print("ğŸ§ª æ­£åœ¨è¿›è¡Œè‡ªå®šä¹‰å› å­å®éªŒ (Precise Config)...")
-        print(f"å› å­æ•°é‡: {len(custom_factors)}")
-
-        # è®­ç»ƒ
-        print("1. åˆå§‹åŒ–æ¨¡å‹ä¸æ•°æ®...")
-        model = init_instance_by_config(task["model"])
-        dataset = init_instance_by_config(task["dataset"])
-
-        print("2. å¼€å§‹è®­ç»ƒ (LightGBM)...")
-        model.fit(dataset)
-
-        # é¢„æµ‹ä¸ICåˆ†æ
-        print("3. é¢„æµ‹ä¸è¯„ä¼°...")
-        recorder = R.get_recorder()
-        pred = model.predict(dataset)
-        label = dataset.prepare(segments="test", col_set="label")
-
-        # ç®€å•å¯¹é½
-        if isinstance(pred, pd.DataFrame): pred = pred.iloc[:, 0]
-        if isinstance(label, pd.DataFrame): label = label.iloc[:, 0]
-
-        idx = pred.index.intersection(label.index)
-        ic = pred.loc[idx].corr(label.loc[idx])
-        rank_ic = pred.loc[idx].rank().corr(label.loc[idx].rank())
-
-        print("-" * 50)
-        print(f"ğŸ“Š å®éªŒç»“æœ (Custom 5 Factors):")
-        print(f"   Rank IC: {rank_ic:.4f}")
-        print("-" * 50)
-
-        if rank_ic > 0.01:
-            print("âœ… å®éªŒæˆåŠŸï¼")
-            print("   è¿™è¯æ˜äº†ä½ å®Œå…¨æŒæ¡äº† Qlib çš„é…ç½®é€»è¾‘ï¼šHandler ç®¡è°ƒåº¦ï¼ŒProcessor ç®¡è®¡ç®—ã€‚")
\ No newline at end of file
+    run_custom_training()
\ No newline at end of file
